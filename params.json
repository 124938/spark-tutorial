{"name":"spark-tutorial","tagline":"This tutorial provides a quick introduction to using Spark","body":"This tutorial provides a quick introduction to using Spark. It demonstrates the basic functionality of RDD and DataFrame API\r\n\r\n#### Initializing Spark\r\n\r\n```scala\r\nval conf = new SparkConf().setAppName(appName).setMaster(master)\r\nnew SparkContext(conf)\r\n```\r\n\r\nCheck [SparkCommon](https://github.com/rklick-solutions/spark-tutorial/blob/master/src/main/scala/com/tutorial/utils/SparkCommon.scala)\r\n\r\n`Note:` Only one SparkContext may be active per JVM. You must stop() the active SparkContext before creating a new one.\r\n\r\nWe have tried to cover basics of Spark Core, SQL, Streaming, ML and GraphX programming contexts.\r\n\r\n#### RDD Functionality\r\n* Creations\r\n* Operations\r\n* Transformations\r\n* Actions\r\n\r\nFor more information [check](https://github.com/rklick-solutions/spark-tutorial/wiki/Spark-Core)\r\n\r\n#### Spark SQL\r\n* Create SQL Context\r\n* Creating DataFrames\r\n* Creating Datasets\r\n* Inferring the Schema using Reflection\r\n* Programmatically Specifying the Schema\r\n* DataFrame Operations in JSON file\r\n* DataFrame Operations in Text file\r\n* DataFrame Operations in CSV file\r\n* DataFarme API\r\n* Action\r\n* Basic DataFrame functions\r\n* DataFrame Operations\r\n\r\nFor more information [check](https://github.com/rklick-solutions/spark-tutorial/wiki/Spark-SQL)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}