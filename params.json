{"name":"spark-tutorial","tagline":"This tutorial provides a quick introduction to using Spark","body":"This tutorial provides a quick introduction to using Spark. It demonstrates the basic functionality of RDD and DataFrame API\r\n\r\n#### Initializing Spark\r\n\r\n```scala\r\nval conf = new SparkConf().setAppName(appName).setMaster(master)\r\nnew SparkContext(conf)\r\n```\r\n\r\nCheck [SparkCommon](https://github.com/rklick-solutions/spark-tutorial/blob/master/src/main/scala/com/tutorial/utils/SparkCommon.scala)\r\n\r\n`Note:` Only one SparkContext may be active per JVM. You must stop() the active SparkContext before creating a new one.\r\n\r\nWe have tried to cover basics of Spark Core, SQL, Streaming, ML and GraphX programming contexts.\r\n\r\n#### RDD Functionality\r\n* Creations\r\n* Transformations\r\n* Actions\r\n* Operations\r\n\r\nFor more information [check](https://github.com/rklick-solutions/spark-tutorial/wiki/Spark-Core)\r\n\r\n\r\n\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}